{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "464c4b63",
   "metadata": {},
   "source": [
    "# üöÄ GPU-ACCELERATED MODEL - FASE 1: QUICK WINS\n",
    "## Target: Migliorare da 13,978 ‚Üí ~9,000-10,000 score\n",
    "\n",
    "**Strategie:**\n",
    "1. CatBoost GPU con 10,000 iterazioni\n",
    "2. XGBoost GPU ottimizzato\n",
    "3. Feature Engineering Avanzato (100+ features)\n",
    "4. Optuna con 1000+ trials\n",
    "5. Ensemble pesante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c15fca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CatBoost available\n",
      "‚ùå Optuna not installed. Run: pip install optuna\n",
      "\n",
      "‚úÖ Core libraries loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/disi/miniconda3/envs/nlu25/lib/python3.10/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# GPU libraries\n",
    "try:\n",
    "    from catboost import CatBoostRegressor, Pool\n",
    "    print(\"‚úÖ CatBoost available\")\n",
    "    CATBOOST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"‚ùå CatBoost not installed. Run: pip install catboost\")\n",
    "    CATBOOST_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    import optuna\n",
    "    from optuna.integration import LightGBMPruningCallback\n",
    "    print(\"‚úÖ Optuna available\")\n",
    "    OPTUNA_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"‚ùå Optuna not installed. Run: pip install optuna\")\n",
    "    OPTUNA_AVAILABLE = False\n",
    "\n",
    "print(\"\\n‚úÖ Core libraries loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "164403c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receivals: 122,590 rows\n",
      "Purchase Orders: 33,171 rows\n",
      "Prediction mapping: 30,450 rows\n",
      "\n",
      "Date range: 2004-06-15 11:34:00 to 2024-12-19 13:36:00\n",
      "Date dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "receivals = pd.read_csv('data/kernel/receivals.csv')\n",
    "purchase_orders = pd.read_csv('data/kernel/purchase_orders.csv')\n",
    "materials = pd.read_csv('data/extended/materials.csv')\n",
    "prediction_mapping = pd.read_csv('data/prediction_mapping.csv')\n",
    "\n",
    "# Convert dates - use utc=True for mixed timezones, then remove timezone\n",
    "receivals['date_arrival'] = pd.to_datetime(receivals['date_arrival'], utc=True).dt.tz_localize(None)\n",
    "purchase_orders['delivery_date'] = pd.to_datetime(purchase_orders['delivery_date'], utc=True).dt.tz_localize(None)\n",
    "\n",
    "print(f\"Receivals: {len(receivals):,} rows\")\n",
    "print(f\"Purchase Orders: {len(purchase_orders):,} rows\")\n",
    "print(f\"Prediction mapping: {len(prediction_mapping):,} rows\")\n",
    "print(f\"\\nDate range: {receivals['date_arrival'].min()} to {receivals['date_arrival'].max()}\")\n",
    "print(f\"Date dtype: {receivals['date_arrival'].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1028b89",
   "metadata": {},
   "source": [
    "## üîß ADVANCED FEATURE ENGINEERING (100+ Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ead25cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Advanced feature engineering function defined\n"
     ]
    }
   ],
   "source": [
    "def calculate_advanced_features_v2(receivals, purchase_orders, materials, rm_id, current_date, forecast_horizon_days):\n",
    "    \"\"\"\n",
    "    Calculate 100+ advanced features\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # Ensure current_date is timezone-naive pandas Timestamp\n",
    "    current_date = pd.Timestamp(current_date)\n",
    "    \n",
    "    # Historical data\n",
    "    hist = receivals[(receivals['rm_id'] == rm_id) & (receivals['date_arrival'] <= current_date)]\n",
    "    \n",
    "    if len(hist) == 0:\n",
    "        return {'rm_id_encoded': rm_id, 'forecast_horizon_days': forecast_horizon_days, 'has_history': 0,\n",
    "                **{f'feature_{i}': 0 for i in range(100)}}\n",
    "    \n",
    "    # Basic\n",
    "    features['rm_id_encoded'] = rm_id\n",
    "    features['forecast_horizon_days'] = forecast_horizon_days\n",
    "    features['has_history'] = 1\n",
    "    features['total_deliveries'] = len(hist)\n",
    "    \n",
    "    # Target date features\n",
    "    target_date = current_date + pd.Timedelta(days=forecast_horizon_days)\n",
    "    features['month'] = target_date.month\n",
    "    features['quarter'] = target_date.quarter\n",
    "    features['day_of_year'] = target_date.dayofyear\n",
    "    features['week_of_year'] = target_date.isocalendar()[1]\n",
    "    features['is_quarter_end'] = int(target_date.month in [3, 6, 9, 12])\n",
    "    features['is_year_end'] = int(target_date.month == 12)\n",
    "    \n",
    "    # Multiple seasonality encodings\n",
    "    features['month_sin'] = np.sin(2 * np.pi * target_date.month / 12)\n",
    "    features['month_cos'] = np.cos(2 * np.pi * target_date.month / 12)\n",
    "    features['quarter_sin'] = np.sin(2 * np.pi * target_date.quarter / 4)\n",
    "    features['quarter_cos'] = np.cos(2 * np.pi * target_date.quarter / 4)\n",
    "    features['week_sin'] = np.sin(2 * np.pi * target_date.isocalendar()[1] / 52)\n",
    "    features['week_cos'] = np.cos(2 * np.pi * target_date.isocalendar()[1] / 52)\n",
    "    \n",
    "    # Historical statistics - MULTIPLE QUANTILES\n",
    "    for q in [0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.50, 0.75, 0.90]:\n",
    "        features[f'hist_p{int(q*100)}'] = hist['net_weight'].quantile(q)\n",
    "    \n",
    "    features['hist_mean'] = hist['net_weight'].mean()\n",
    "    features['hist_std'] = hist['net_weight'].std()\n",
    "    features['hist_cv'] = features['hist_std'] / (features['hist_mean'] + 1)\n",
    "    features['hist_skew'] = hist['net_weight'].skew()\n",
    "    features['hist_kurt'] = hist['net_weight'].kurtosis()\n",
    "    \n",
    "    # ROLLING WINDOWS - Multiple periods\n",
    "    for window in [7, 14, 30, 60, 90, 180, 365]:\n",
    "        recent = hist[hist['date_arrival'] >= (current_date - pd.Timedelta(days=window))]\n",
    "        \n",
    "        if len(recent) > 0:\n",
    "            features[f'roll_{window}d_mean'] = recent['net_weight'].mean()\n",
    "            features[f'roll_{window}d_std'] = recent['net_weight'].std()\n",
    "            features[f'roll_{window}d_p10'] = recent['net_weight'].quantile(0.10)\n",
    "            features[f'roll_{window}d_p20'] = recent['net_weight'].quantile(0.20)\n",
    "            features[f'roll_{window}d_p50'] = recent['net_weight'].quantile(0.50)\n",
    "            features[f'roll_{window}d_count'] = len(recent)\n",
    "            features[f'roll_{window}d_sum'] = recent['net_weight'].sum()\n",
    "            features[f'roll_{window}d_daily_rate'] = recent['net_weight'].sum() / window\n",
    "            \n",
    "            # Trend (linear regression)\n",
    "            if len(recent) > 2:\n",
    "                x = np.arange(len(recent))\n",
    "                y = recent['net_weight'].values\n",
    "                slope = np.polyfit(x, y, 1)[0] if len(x) > 0 else 0\n",
    "                features[f'roll_{window}d_trend'] = slope\n",
    "            else:\n",
    "                features[f'roll_{window}d_trend'] = 0\n",
    "        else:\n",
    "            features[f'roll_{window}d_mean'] = 0\n",
    "            features[f'roll_{window}d_std'] = 0\n",
    "            features[f'roll_{window}d_p10'] = 0\n",
    "            features[f'roll_{window}d_p20'] = 0\n",
    "            features[f'roll_{window}d_p50'] = 0\n",
    "            features[f'roll_{window}d_count'] = 0\n",
    "            features[f'roll_{window}d_sum'] = 0\n",
    "            features[f'roll_{window}d_daily_rate'] = 0\n",
    "            features[f'roll_{window}d_trend'] = 0\n",
    "    \n",
    "    # LAG FEATURES\n",
    "    hist_sorted = hist.sort_values('date_arrival', ascending=False)\n",
    "    for lag in [1, 7, 14, 30, 60, 90]:\n",
    "        lag_data = hist_sorted[hist_sorted['date_arrival'] <= (current_date - pd.Timedelta(days=lag))]\n",
    "        if len(lag_data) > 0:\n",
    "            features[f'lag_{lag}d_weight'] = lag_data.iloc[0]['net_weight']\n",
    "        else:\n",
    "            features[f'lag_{lag}d_weight'] = 0\n",
    "    \n",
    "    # Delivery frequency\n",
    "    if len(hist) > 1:\n",
    "        date_range = (hist['date_arrival'].max() - hist['date_arrival'].min()).days\n",
    "        features['delivery_frequency'] = len(hist) / max(date_range, 1)\n",
    "        features['avg_days_between'] = date_range / max(len(hist) - 1, 1)\n",
    "    else:\n",
    "        features['delivery_frequency'] = 0\n",
    "        features['avg_days_between'] = 999\n",
    "    \n",
    "    # Days since last delivery\n",
    "    features['days_since_last'] = (current_date - hist['date_arrival'].max()).days\n",
    "    features['recency_score'] = 1 / (1 + features['days_since_last'] / 30)  # Decay factor\n",
    "    \n",
    "    # Purchase orders\n",
    "    rm_products = materials[materials['rm_id'] == rm_id]['product_id'].dropna().unique()\n",
    "    \n",
    "    if len(rm_products) > 0:\n",
    "        future_orders = purchase_orders[\n",
    "            (purchase_orders['product_id'].isin(rm_products)) &\n",
    "            (purchase_orders['delivery_date'] > current_date) &\n",
    "            (purchase_orders['delivery_date'] <= target_date)\n",
    "        ]\n",
    "        \n",
    "        features['future_orders_count'] = len(future_orders)\n",
    "        features['future_orders_qty'] = future_orders['quantity'].sum() if len(future_orders) > 0 else 0\n",
    "        features['future_orders_avg'] = future_orders['quantity'].mean() if len(future_orders) > 0 else 0\n",
    "    else:\n",
    "        features['future_orders_count'] = 0\n",
    "        features['future_orders_qty'] = 0\n",
    "        features['future_orders_avg'] = 0\n",
    "    \n",
    "    # INTERACTION FEATURES\n",
    "    features['horizon_x_freq'] = forecast_horizon_days * features['delivery_frequency']\n",
    "    features['horizon_x_recency'] = forecast_horizon_days * features['recency_score']\n",
    "    features['horizon_x_trend_30'] = forecast_horizon_days * features['roll_30d_trend']\n",
    "    features['month_x_p20'] = features['month'] * features['hist_p20']\n",
    "    \n",
    "    # MOMENTUM features\n",
    "    features['momentum_30_60'] = features['roll_30d_mean'] - features['roll_60d_mean']\n",
    "    features['momentum_60_90'] = features['roll_60d_mean'] - features['roll_90d_mean']\n",
    "    features['acceleration'] = features['momentum_30_60'] - features['momentum_60_90']\n",
    "    \n",
    "    return features\n",
    "\n",
    "print(\"‚úÖ Advanced feature engineering function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb7dc4c",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Create Training Dataset (50,000 samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5cc055a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 15,000 training samples from 103 materials...\n",
      "This will take ~5-10 minutes...\n",
      "  5,000/15,000 samples...\n",
      "  5,000/15,000 samples...\n",
      "  10,000/15,000 samples...\n",
      "  10,000/15,000 samples...\n",
      "  15,000/15,000 samples...\n",
      "  15,000/15,000 samples...\n",
      "\n",
      "‚úÖ Created 15,000 samples\n",
      "Features: 113\n",
      "Target stats: mean=615,043, p20=22,372\n",
      "\n",
      "‚úÖ Created 15,000 samples\n",
      "Features: 113\n",
      "Target stats: mean=615,043, p20=22,372\n"
     ]
    }
   ],
   "source": [
    "def create_gpu_training_samples(receivals, purchase_orders, materials, n_samples=50000):\n",
    "    \"\"\"\n",
    "    Create massive training dataset for GPU training\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    samples = []\n",
    "    \n",
    "    material_counts = receivals['rm_id'].value_counts()\n",
    "    valid_materials = material_counts[material_counts >= 20].index.tolist()\n",
    "    \n",
    "    print(f\"Creating {n_samples:,} training samples from {len(valid_materials)} materials...\")\n",
    "    print(\"This will take ~5-10 minutes...\")\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        if (i + 1) % 5000 == 0:\n",
    "            print(f\"  {i + 1:,}/{n_samples:,} samples...\")\n",
    "        \n",
    "        rm_id = np.random.choice(valid_materials)\n",
    "        rm_data = receivals[receivals['rm_id'] == rm_id].sort_values('date_arrival')\n",
    "        \n",
    "        if len(rm_data) < 20:\n",
    "            continue\n",
    "        \n",
    "        split_idx = np.random.randint(int(len(rm_data) * 0.5), int(len(rm_data) * 0.95))\n",
    "        current_date = rm_data.iloc[split_idx]['date_arrival']\n",
    "        horizon_days = np.random.randint(1, 151)\n",
    "        target_date = current_date + pd.Timedelta(days=horizon_days)\n",
    "        \n",
    "        features = calculate_advanced_features_v2(\n",
    "            rm_data.iloc[:split_idx],\n",
    "            purchase_orders,\n",
    "            materials,\n",
    "            rm_id,\n",
    "            current_date,\n",
    "            horizon_days\n",
    "        )\n",
    "        \n",
    "        actual = rm_data[\n",
    "            (rm_data['date_arrival'] > current_date) &\n",
    "            (rm_data['date_arrival'] <= target_date)\n",
    "        ]['net_weight'].sum()\n",
    "        \n",
    "        features['target'] = actual\n",
    "        samples.append(features)\n",
    "    \n",
    "    df = pd.DataFrame(samples)\n",
    "    print(f\"\\n‚úÖ Created {len(df):,} samples\")\n",
    "    print(f\"Features: {len([c for c in df.columns if c != 'target'])}\")\n",
    "    print(f\"Target stats: mean={df['target'].mean():,.0f}, p20={df['target'].quantile(0.20):,.0f}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# NOTE: Start with 15K samples for testing, then increase to 50K for final training\n",
    "train_df_gpu = create_gpu_training_samples(receivals, purchase_orders, materials, n_samples=15000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c701e9f2",
   "metadata": {},
   "source": [
    "## üöÄ CATBOOST GPU MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71157168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 11,250\n",
      "Validation samples: 3,750\n",
      "Features: 113\n",
      "\n",
      "üöÄ Training CatBoost GPU model...\n",
      "This will take 5-15 minutes depending on GPU...\n",
      "\n",
      "0:\tlearn: 123423.0727111\ttest: 117678.1141333\tbest: 117678.1141333 (0)\ttotal: 34ms\tremaining: 2m 49s\n",
      "0:\tlearn: 123423.0727111\ttest: 117678.1141333\tbest: 117678.1141333 (0)\ttotal: 34ms\tremaining: 2m 49s\n",
      "100:\tlearn: 123422.7427556\ttest: 117677.7728000\tbest: 117677.7728000 (96)\ttotal: 2.18s\tremaining: 1m 45s\n",
      "100:\tlearn: 123422.7427556\ttest: 117677.7728000\tbest: 117677.7728000 (96)\ttotal: 2.18s\tremaining: 1m 45s\n",
      "200:\tlearn: 123422.4014222\ttest: 117677.4229333\tbest: 117677.4229333 (200)\ttotal: 4.15s\tremaining: 1m 39s\n",
      "200:\tlearn: 123422.4014222\ttest: 117677.4229333\tbest: 117677.4229333 (200)\ttotal: 4.15s\tremaining: 1m 39s\n",
      "300:\tlearn: 123422.0714667\ttest: 117677.0816000\tbest: 117677.0816000 (298)\ttotal: 6.18s\tremaining: 1m 36s\n",
      "300:\tlearn: 123422.0714667\ttest: 117677.0816000\tbest: 117677.0816000 (298)\ttotal: 6.18s\tremaining: 1m 36s\n",
      "400:\tlearn: 123421.7187556\ttest: 117676.7232000\tbest: 117676.7232000 (400)\ttotal: 8.32s\tremaining: 1m 35s\n",
      "400:\tlearn: 123421.7187556\ttest: 117676.7232000\tbest: 117676.7232000 (400)\ttotal: 8.32s\tremaining: 1m 35s\n",
      "500:\tlearn: 123421.3774222\ttest: 117676.3733333\tbest: 117676.3733333 (499)\ttotal: 10.4s\tremaining: 1m 33s\n",
      "500:\tlearn: 123421.3774222\ttest: 117676.3733333\tbest: 117676.3733333 (499)\ttotal: 10.4s\tremaining: 1m 33s\n",
      "600:\tlearn: 123421.0133333\ttest: 117676.0149333\tbest: 117676.0149333 (599)\ttotal: 12.6s\tremaining: 1m 32s\n",
      "600:\tlearn: 123421.0133333\ttest: 117676.0149333\tbest: 117676.0149333 (599)\ttotal: 12.6s\tremaining: 1m 32s\n",
      "700:\tlearn: 123420.6720000\ttest: 117675.6736000\tbest: 117675.6736000 (698)\ttotal: 14.8s\tremaining: 1m 30s\n",
      "700:\tlearn: 123420.6720000\ttest: 117675.6736000\tbest: 117675.6736000 (698)\ttotal: 14.8s\tremaining: 1m 30s\n",
      "800:\tlearn: 123420.3192889\ttest: 117675.3152000\tbest: 117675.3152000 (797)\ttotal: 16.9s\tremaining: 1m 28s\n",
      "800:\tlearn: 123420.3192889\ttest: 117675.3152000\tbest: 117675.3152000 (797)\ttotal: 16.9s\tremaining: 1m 28s\n",
      "900:\tlearn: 123419.9665778\ttest: 117674.9568000\tbest: 117674.9568000 (900)\ttotal: 19s\tremaining: 1m 26s\n",
      "900:\tlearn: 123419.9665778\ttest: 117674.9568000\tbest: 117674.9568000 (900)\ttotal: 19s\tremaining: 1m 26s\n",
      "1000:\tlearn: 123419.6252444\ttest: 117674.6069333\tbest: 117674.6069333 (999)\ttotal: 21.2s\tremaining: 1m 24s\n",
      "1000:\tlearn: 123419.6252444\ttest: 117674.6069333\tbest: 117674.6069333 (999)\ttotal: 21.2s\tremaining: 1m 24s\n",
      "1100:\tlearn: 123419.2611556\ttest: 117674.2570667\tbest: 117674.2570667 (1096)\ttotal: 23.3s\tremaining: 1m 22s\n",
      "1100:\tlearn: 123419.2611556\ttest: 117674.2570667\tbest: 117674.2570667 (1096)\ttotal: 23.3s\tremaining: 1m 22s\n",
      "1200:\tlearn: 123418.9198222\ttest: 117673.8901333\tbest: 117673.8901333 (1200)\ttotal: 25.5s\tremaining: 1m 20s\n",
      "1200:\tlearn: 123418.9198222\ttest: 117673.8901333\tbest: 117673.8901333 (1200)\ttotal: 25.5s\tremaining: 1m 20s\n",
      "1300:\tlearn: 123418.5784889\ttest: 117673.5488000\tbest: 117673.5488000 (1298)\ttotal: 27.7s\tremaining: 1m 18s\n",
      "1300:\tlearn: 123418.5784889\ttest: 117673.5488000\tbest: 117673.5488000 (1298)\ttotal: 27.7s\tremaining: 1m 18s\n",
      "1400:\tlearn: 123418.2257778\ttest: 117673.1989333\tbest: 117673.1989333 (1396)\ttotal: 29.9s\tremaining: 1m 16s\n",
      "1400:\tlearn: 123418.2257778\ttest: 117673.1989333\tbest: 117673.1989333 (1396)\ttotal: 29.9s\tremaining: 1m 16s\n",
      "1500:\tlearn: 123417.8844444\ttest: 117672.8405333\tbest: 117672.8405333 (1495)\ttotal: 32s\tremaining: 1m 14s\n",
      "1500:\tlearn: 123417.8844444\ttest: 117672.8405333\tbest: 117672.8405333 (1495)\ttotal: 32s\tremaining: 1m 14s\n",
      "1600:\tlearn: 123417.5203556\ttest: 117672.4821333\tbest: 117672.4821333 (1599)\ttotal: 34.2s\tremaining: 1m 12s\n",
      "1600:\tlearn: 123417.5203556\ttest: 117672.4821333\tbest: 117672.4821333 (1599)\ttotal: 34.2s\tremaining: 1m 12s\n",
      "1700:\tlearn: 123417.1676444\ttest: 117672.1322667\tbest: 117672.1322667 (1698)\ttotal: 36.3s\tremaining: 1m 10s\n",
      "1700:\tlearn: 123417.1676444\ttest: 117672.1322667\tbest: 117672.1322667 (1698)\ttotal: 36.3s\tremaining: 1m 10s\n",
      "1800:\tlearn: 123416.8490667\ttest: 117671.7738667\tbest: 117671.7738667 (1800)\ttotal: 38.5s\tremaining: 1m 8s\n",
      "1800:\tlearn: 123416.8490667\ttest: 117671.7738667\tbest: 117671.7738667 (1800)\ttotal: 38.5s\tremaining: 1m 8s\n",
      "1900:\tlearn: 123416.4849778\ttest: 117671.4240000\tbest: 117671.4240000 (1898)\ttotal: 40.6s\tremaining: 1m 6s\n",
      "1900:\tlearn: 123416.4849778\ttest: 117671.4240000\tbest: 117671.4240000 (1898)\ttotal: 40.6s\tremaining: 1m 6s\n",
      "2000:\tlearn: 123416.1322667\ttest: 117671.0656000\tbest: 117671.0656000 (2000)\ttotal: 42.9s\tremaining: 1m 4s\n",
      "2000:\tlearn: 123416.1322667\ttest: 117671.0656000\tbest: 117671.0656000 (2000)\ttotal: 42.9s\tremaining: 1m 4s\n",
      "2100:\tlearn: 123415.8023111\ttest: 117670.7072000\tbest: 117670.7072000 (2100)\ttotal: 45s\tremaining: 1m 2s\n",
      "2100:\tlearn: 123415.8023111\ttest: 117670.7072000\tbest: 117670.7072000 (2100)\ttotal: 45s\tremaining: 1m 2s\n",
      "2200:\tlearn: 123415.4268444\ttest: 117670.3488000\tbest: 117670.3488000 (2200)\ttotal: 47.2s\tremaining: 1m\n",
      "2200:\tlearn: 123415.4268444\ttest: 117670.3488000\tbest: 117670.3488000 (2200)\ttotal: 47.2s\tremaining: 1m\n",
      "2300:\tlearn: 123415.0855111\ttest: 117670.0074667\tbest: 117670.0074667 (2300)\ttotal: 49.4s\tremaining: 57.9s\n",
      "2300:\tlearn: 123415.0855111\ttest: 117670.0074667\tbest: 117670.0074667 (2300)\ttotal: 49.4s\tremaining: 57.9s\n",
      "2400:\tlearn: 123414.7441778\ttest: 117669.6576000\tbest: 117669.6576000 (2398)\ttotal: 51.5s\tremaining: 55.8s\n",
      "2400:\tlearn: 123414.7441778\ttest: 117669.6576000\tbest: 117669.6576000 (2398)\ttotal: 51.5s\tremaining: 55.8s\n",
      "2500:\tlearn: 123414.3800889\ttest: 117669.3077333\tbest: 117669.3077333 (2499)\ttotal: 53.7s\tremaining: 53.7s\n",
      "2500:\tlearn: 123414.3800889\ttest: 117669.3077333\tbest: 117669.3077333 (2499)\ttotal: 53.7s\tremaining: 53.7s\n",
      "2600:\tlearn: 123414.0273778\ttest: 117668.9493333\tbest: 117668.9493333 (2599)\ttotal: 55.8s\tremaining: 51.5s\n",
      "2600:\tlearn: 123414.0273778\ttest: 117668.9493333\tbest: 117668.9493333 (2599)\ttotal: 55.8s\tremaining: 51.5s\n",
      "2700:\tlearn: 123413.6860444\ttest: 117668.5909333\tbest: 117668.5909333 (2700)\ttotal: 58s\tremaining: 49.4s\n",
      "2700:\tlearn: 123413.6860444\ttest: 117668.5909333\tbest: 117668.5909333 (2700)\ttotal: 58s\tremaining: 49.4s\n",
      "2800:\tlearn: 123413.3333333\ttest: 117668.2410667\tbest: 117668.2410667 (2799)\ttotal: 1m\tremaining: 47.3s\n",
      "2800:\tlearn: 123413.3333333\ttest: 117668.2410667\tbest: 117668.2410667 (2799)\ttotal: 1m\tremaining: 47.3s\n",
      "2900:\tlearn: 123412.9920000\ttest: 117667.8912000\tbest: 117667.8912000 (2899)\ttotal: 1m 2s\tremaining: 45.1s\n",
      "2900:\tlearn: 123412.9920000\ttest: 117667.8912000\tbest: 117667.8912000 (2899)\ttotal: 1m 2s\tremaining: 45.1s\n",
      "3000:\tlearn: 123412.6506667\ttest: 117667.5328000\tbest: 117667.5328000 (2999)\ttotal: 1m 4s\tremaining: 43s\n",
      "3000:\tlearn: 123412.6506667\ttest: 117667.5328000\tbest: 117667.5328000 (2999)\ttotal: 1m 4s\tremaining: 43s\n",
      "3100:\tlearn: 123412.3093333\ttest: 117667.1829333\tbest: 117667.1829333 (3100)\ttotal: 1m 6s\tremaining: 40.9s\n",
      "3100:\tlearn: 123412.3093333\ttest: 117667.1829333\tbest: 117667.1829333 (3100)\ttotal: 1m 6s\tremaining: 40.9s\n",
      "3200:\tlearn: 123411.9566222\ttest: 117666.8330667\tbest: 117666.8330667 (3198)\ttotal: 1m 8s\tremaining: 38.7s\n",
      "3200:\tlearn: 123411.9566222\ttest: 117666.8330667\tbest: 117666.8330667 (3198)\ttotal: 1m 8s\tremaining: 38.7s\n",
      "3300:\tlearn: 123411.6039111\ttest: 117666.4746667\tbest: 117666.4746667 (3299)\ttotal: 1m 10s\tremaining: 36.5s\n",
      "3300:\tlearn: 123411.6039111\ttest: 117666.4746667\tbest: 117666.4746667 (3299)\ttotal: 1m 10s\tremaining: 36.5s\n",
      "3400:\tlearn: 123411.2512000\ttest: 117666.1162667\tbest: 117666.1162667 (3399)\ttotal: 1m 13s\tremaining: 34.4s\n",
      "3400:\tlearn: 123411.2512000\ttest: 117666.1162667\tbest: 117666.1162667 (3399)\ttotal: 1m 13s\tremaining: 34.4s\n",
      "3500:\tlearn: 123410.9098667\ttest: 117665.7664000\tbest: 117665.7664000 (3500)\ttotal: 1m 15s\tremaining: 32.2s\n",
      "3500:\tlearn: 123410.9098667\ttest: 117665.7664000\tbest: 117665.7664000 (3500)\ttotal: 1m 15s\tremaining: 32.2s\n",
      "3600:\tlearn: 123410.5685333\ttest: 117665.4250667\tbest: 117665.4250667 (3600)\ttotal: 1m 17s\tremaining: 30.1s\n",
      "3600:\tlearn: 123410.5685333\ttest: 117665.4250667\tbest: 117665.4250667 (3600)\ttotal: 1m 17s\tremaining: 30.1s\n",
      "3700:\tlearn: 123410.1930667\ttest: 117665.0666667\tbest: 117665.0666667 (3700)\ttotal: 1m 19s\tremaining: 28s\n",
      "3700:\tlearn: 123410.1930667\ttest: 117665.0666667\tbest: 117665.0666667 (3700)\ttotal: 1m 19s\tremaining: 28s\n",
      "3800:\tlearn: 123409.8631111\ttest: 117664.7168000\tbest: 117664.7168000 (3797)\ttotal: 1m 21s\tremaining: 25.8s\n",
      "3800:\tlearn: 123409.8631111\ttest: 117664.7168000\tbest: 117664.7168000 (3797)\ttotal: 1m 21s\tremaining: 25.8s\n",
      "3900:\tlearn: 123409.5104000\ttest: 117664.3584000\tbest: 117664.3584000 (3898)\ttotal: 1m 23s\tremaining: 23.6s\n",
      "3900:\tlearn: 123409.5104000\ttest: 117664.3584000\tbest: 117664.3584000 (3898)\ttotal: 1m 23s\tremaining: 23.6s\n",
      "4000:\tlearn: 123409.1576889\ttest: 117664.0000000\tbest: 117664.0000000 (4000)\ttotal: 1m 26s\tremaining: 21.5s\n",
      "4000:\tlearn: 123409.1576889\ttest: 117664.0000000\tbest: 117664.0000000 (4000)\ttotal: 1m 26s\tremaining: 21.5s\n",
      "4100:\tlearn: 123408.8163556\ttest: 117663.6586667\tbest: 117663.6586667 (4099)\ttotal: 1m 28s\tremaining: 19.4s\n",
      "4100:\tlearn: 123408.8163556\ttest: 117663.6586667\tbest: 117663.6586667 (4099)\ttotal: 1m 28s\tremaining: 19.4s\n",
      "4200:\tlearn: 123408.4750222\ttest: 117663.3088000\tbest: 117663.3002667 (4199)\ttotal: 1m 30s\tremaining: 17.2s\n",
      "4200:\tlearn: 123408.4750222\ttest: 117663.3088000\tbest: 117663.3002667 (4199)\ttotal: 1m 30s\tremaining: 17.2s\n",
      "4300:\tlearn: 123408.1223111\ttest: 117662.9418667\tbest: 117662.9418667 (4299)\ttotal: 1m 32s\tremaining: 15s\n",
      "4300:\tlearn: 123408.1223111\ttest: 117662.9418667\tbest: 117662.9418667 (4299)\ttotal: 1m 32s\tremaining: 15s\n",
      "4400:\tlearn: 123407.7696000\ttest: 117662.5920000\tbest: 117662.5920000 (4400)\ttotal: 1m 34s\tremaining: 12.9s\n",
      "4400:\tlearn: 123407.7696000\ttest: 117662.5920000\tbest: 117662.5920000 (4400)\ttotal: 1m 34s\tremaining: 12.9s\n",
      "4500:\tlearn: 123407.4282667\ttest: 117662.2421333\tbest: 117662.2421333 (4500)\ttotal: 1m 36s\tremaining: 10.8s\n",
      "4500:\tlearn: 123407.4282667\ttest: 117662.2421333\tbest: 117662.2421333 (4500)\ttotal: 1m 36s\tremaining: 10.8s\n",
      "4600:\tlearn: 123407.0869333\ttest: 117661.8837333\tbest: 117661.8837333 (4599)\ttotal: 1m 39s\tremaining: 8.6s\n",
      "4600:\tlearn: 123407.0869333\ttest: 117661.8837333\tbest: 117661.8837333 (4599)\ttotal: 1m 39s\tremaining: 8.6s\n",
      "4700:\tlearn: 123406.7456000\ttest: 117661.5424000\tbest: 117661.5424000 (4696)\ttotal: 1m 41s\tremaining: 6.44s\n",
      "4700:\tlearn: 123406.7456000\ttest: 117661.5424000\tbest: 117661.5424000 (4696)\ttotal: 1m 41s\tremaining: 6.44s\n",
      "4800:\tlearn: 123406.3815111\ttest: 117661.1840000\tbest: 117661.1840000 (4798)\ttotal: 1m 43s\tremaining: 4.29s\n",
      "4800:\tlearn: 123406.3815111\ttest: 117661.1840000\tbest: 117661.1840000 (4798)\ttotal: 1m 43s\tremaining: 4.29s\n",
      "4900:\tlearn: 123406.0401778\ttest: 117660.8341333\tbest: 117660.8341333 (4898)\ttotal: 1m 45s\tremaining: 2.13s\n",
      "4900:\tlearn: 123406.0401778\ttest: 117660.8341333\tbest: 117660.8341333 (4898)\ttotal: 1m 45s\tremaining: 2.13s\n",
      "4999:\tlearn: 123405.6988444\ttest: 117660.4842667\tbest: 117660.4842667 (4998)\ttotal: 1m 47s\tremaining: 0us\n",
      "bestTest = 117660.4843\n",
      "bestIteration = 4998\n",
      "Shrink model to first 4999 iterations.\n",
      "4999:\tlearn: 123405.6988444\ttest: 117660.4842667\tbest: 117660.4842667 (4998)\ttotal: 1m 47s\tremaining: 0us\n",
      "bestTest = 117660.4843\n",
      "bestIteration = 4998\n",
      "Shrink model to first 4999 iterations.\n",
      "\n",
      "‚úÖ CatBoost model trained!\n",
      "Best iteration: 4998\n",
      "Best score: 117,660.48\n",
      "\n",
      "‚úÖ CatBoost model trained!\n",
      "Best iteration: 4998\n",
      "Best score: 117,660.48\n"
     ]
    }
   ],
   "source": [
    "if not CATBOOST_AVAILABLE:\n",
    "    print(\"‚ö†Ô∏è CatBoost not available. Skipping...\")\n",
    "else:\n",
    "    # Prepare data\n",
    "    feature_cols = [col for col in train_df_gpu.columns if col != 'target']\n",
    "    X = train_df_gpu[feature_cols].fillna(0)\n",
    "    y = train_df_gpu['target']\n",
    "    \n",
    "    # Time series split\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    for train_idx, val_idx in tscv.split(X):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    print(f\"Training samples: {len(X_train):,}\")\n",
    "    print(f\"Validation samples: {len(X_val):,}\")\n",
    "    print(f\"Features: {len(feature_cols)}\")\n",
    "    \n",
    "    # CatBoost GPU params - AGGRESSIVE!\n",
    "    params_catboost = {\n",
    "        'loss_function': 'Quantile:alpha=0.2',\n",
    "        'eval_metric': 'Quantile:alpha=0.2',\n",
    "        'task_type': 'GPU',  # Use GPU!\n",
    "        'devices': '0',\n",
    "        'iterations': 5000,  # Much more iterations\n",
    "        'depth': 8,\n",
    "        'learning_rate': 0.03,\n",
    "        'l2_leaf_reg': 3,\n",
    "        'bootstrap_type': 'Bayesian',\n",
    "        'random_strength': 1,\n",
    "        'bagging_temperature': 1,\n",
    "        'od_type': 'Iter',\n",
    "        'od_wait': 100,\n",
    "        'random_seed': 42,\n",
    "        'verbose': 100\n",
    "    }\n",
    "    \n",
    "    print(\"\\nüöÄ Training CatBoost GPU model...\")\n",
    "    print(\"This will take 5-15 minutes depending on GPU...\\n\")\n",
    "    \n",
    "    model_catboost = CatBoostRegressor(**params_catboost)\n",
    "    model_catboost.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=(X_val, y_val),\n",
    "        use_best_model=True,\n",
    "        plot=False\n",
    "    )\n",
    "    \n",
    "    print(\"\\n‚úÖ CatBoost model trained!\")\n",
    "    print(f\"Best iteration: {model_catboost.get_best_iteration()}\")\n",
    "    print(f\"Best score: {model_catboost.get_best_score()['validation']['Quantile:alpha=0.2']:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e766211",
   "metadata": {},
   "source": [
    "## ‚ö° XGBOOST GPU MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60dc7f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Training XGBoost GPU model...\n",
      "\n",
      "[0]\tvalidation-quantile:117219.99941\n",
      "[0]\tvalidation-quantile:117219.99941\n",
      "[100]\tvalidation-quantile:72461.24700\n",
      "[100]\tvalidation-quantile:72461.24700\n",
      "[200]\tvalidation-quantile:54269.49946\n",
      "[200]\tvalidation-quantile:54269.49946\n",
      "[300]\tvalidation-quantile:48993.32575\n",
      "[300]\tvalidation-quantile:48993.32575\n",
      "[400]\tvalidation-quantile:45831.11263\n",
      "[400]\tvalidation-quantile:45831.11263\n",
      "[500]\tvalidation-quantile:43491.49168\n",
      "[500]\tvalidation-quantile:43491.49168\n",
      "[600]\tvalidation-quantile:41732.29379\n",
      "[600]\tvalidation-quantile:41732.29379\n",
      "[700]\tvalidation-quantile:40187.60315\n",
      "[700]\tvalidation-quantile:40187.60315\n",
      "[800]\tvalidation-quantile:39093.56205\n",
      "[800]\tvalidation-quantile:39093.56205\n",
      "[900]\tvalidation-quantile:38579.09755\n",
      "[900]\tvalidation-quantile:38579.09755\n",
      "[1000]\tvalidation-quantile:38079.17648\n",
      "[1000]\tvalidation-quantile:38079.17648\n",
      "[1100]\tvalidation-quantile:37898.47055\n",
      "[1100]\tvalidation-quantile:37898.47055\n",
      "[1200]\tvalidation-quantile:37394.71212\n",
      "[1200]\tvalidation-quantile:37394.71212\n",
      "[1300]\tvalidation-quantile:36929.44441\n",
      "[1300]\tvalidation-quantile:36929.44441\n",
      "[1400]\tvalidation-quantile:36669.07489\n",
      "[1400]\tvalidation-quantile:36669.07489\n",
      "[1500]\tvalidation-quantile:36422.42332\n",
      "[1500]\tvalidation-quantile:36422.42332\n",
      "[1600]\tvalidation-quantile:36219.77056\n",
      "[1600]\tvalidation-quantile:36219.77056\n",
      "[1700]\tvalidation-quantile:36112.25651\n",
      "[1700]\tvalidation-quantile:36112.25651\n",
      "[1800]\tvalidation-quantile:35927.04556\n",
      "[1800]\tvalidation-quantile:35927.04556\n",
      "[1900]\tvalidation-quantile:35631.46608\n",
      "[1900]\tvalidation-quantile:35631.46608\n",
      "[2000]\tvalidation-quantile:35486.41895\n",
      "[2000]\tvalidation-quantile:35486.41895\n",
      "[2100]\tvalidation-quantile:35305.98778\n",
      "[2100]\tvalidation-quantile:35305.98778\n",
      "[2200]\tvalidation-quantile:35239.09549\n",
      "[2200]\tvalidation-quantile:35239.09549\n",
      "[2300]\tvalidation-quantile:35231.71257\n",
      "[2300]\tvalidation-quantile:35231.71257\n",
      "[2400]\tvalidation-quantile:35079.57600\n",
      "[2400]\tvalidation-quantile:35079.57600\n",
      "[2500]\tvalidation-quantile:34958.14706\n",
      "[2500]\tvalidation-quantile:34958.14706\n",
      "[2600]\tvalidation-quantile:34913.59333\n",
      "[2600]\tvalidation-quantile:34913.59333\n",
      "[2700]\tvalidation-quantile:34883.59362\n",
      "[2700]\tvalidation-quantile:34883.59362\n",
      "[2800]\tvalidation-quantile:34830.74801\n",
      "[2800]\tvalidation-quantile:34830.74801\n",
      "[2900]\tvalidation-quantile:34806.70077\n",
      "[2900]\tvalidation-quantile:34806.70077\n",
      "[2999]\tvalidation-quantile:34769.44386\n",
      "[2999]\tvalidation-quantile:34769.44386\n",
      "\n",
      "‚úÖ XGBoost GPU model trained!\n",
      "Best iteration: 2994\n",
      "\n",
      "‚úÖ XGBoost GPU model trained!\n",
      "Best iteration: 2994\n"
     ]
    }
   ],
   "source": [
    "# XGBoost GPU\n",
    "params_xgb_gpu = {\n",
    "    'objective': 'reg:quantileerror',\n",
    "    'quantile_alpha': 0.2,\n",
    "    'tree_method': 'hist',  # Use 'gpu_hist' if GPU available\n",
    "    'device': 'cuda',  # Use GPU\n",
    "    'max_depth': 8,\n",
    "    'learning_rate': 0.03,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_alpha': 1,\n",
    "    'reg_lambda': 2,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "print(\"üöÄ Training XGBoost GPU model...\\n\")\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "model_xgb = xgb.train(\n",
    "    params_xgb_gpu,\n",
    "    dtrain,\n",
    "    num_boost_round=3000,\n",
    "    evals=[(dval, 'validation')],\n",
    "    early_stopping_rounds=100,\n",
    "    verbose_eval=100\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ XGBoost GPU model trained!\")\n",
    "print(f\"Best iteration: {model_xgb.best_iteration}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fe92aa",
   "metadata": {},
   "source": [
    "## üìä Validation Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "313324e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "VALIDATION RESULTS\n",
      "======================================================================\n",
      "\n",
      "CatBoost GPU:\n",
      "  Quantile Loss: 441,226,701\n",
      "  Mean prediction: 22,479 kg\n",
      "  Under-predictions: 79.7%\n",
      "\n",
      "XGBoost GPU:\n",
      "  Quantile Loss: 130,363,933\n",
      "  Mean prediction: 500,064 kg\n",
      "  Under-predictions: 60.8%\n",
      "\n",
      "Ensemble (avg):\n",
      "  Quantile Loss: 259,752,701\n",
      "  Mean prediction: 261,272 kg\n",
      "  Under-predictions: 77.0%\n",
      "\n",
      "======================================================================\n",
      "Target: 75-80% under-predictions for quantile 0.2\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "def quantile_loss(y_true, y_pred, quantile=0.2):\n",
    "    errors = y_true - y_pred\n",
    "    loss = np.where(errors >= 0, quantile * errors, (quantile - 1) * errors)\n",
    "    return loss.sum()\n",
    "\n",
    "# Predictions\n",
    "if CATBOOST_AVAILABLE:\n",
    "    preds_catboost = model_catboost.predict(X_val)\n",
    "    preds_catboost = np.maximum(preds_catboost, 0)\n",
    "    ql_catboost = quantile_loss(y_val.values, preds_catboost)\n",
    "\n",
    "preds_xgb = model_xgb.predict(dval)\n",
    "preds_xgb = np.maximum(preds_xgb, 0)\n",
    "ql_xgb = quantile_loss(y_val.values, preds_xgb)\n",
    "\n",
    "# Ensemble (simple average)\n",
    "if CATBOOST_AVAILABLE:\n",
    "    preds_ensemble = (preds_catboost + preds_xgb) / 2\n",
    "else:\n",
    "    preds_ensemble = preds_xgb\n",
    "    \n",
    "ql_ensemble = quantile_loss(y_val.values, preds_ensemble)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"VALIDATION RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if CATBOOST_AVAILABLE:\n",
    "    print(f\"\\nCatBoost GPU:\")\n",
    "    print(f\"  Quantile Loss: {ql_catboost:,.0f}\")\n",
    "    print(f\"  Mean prediction: {preds_catboost.mean():,.0f} kg\")\n",
    "    print(f\"  Under-predictions: {np.sum(preds_catboost < y_val.values)/len(y_val):.1%}\")\n",
    "\n",
    "print(f\"\\nXGBoost GPU:\")\n",
    "print(f\"  Quantile Loss: {ql_xgb:,.0f}\")\n",
    "print(f\"  Mean prediction: {preds_xgb.mean():,.0f} kg\")\n",
    "print(f\"  Under-predictions: {np.sum(preds_xgb < y_val.values)/len(y_val):.1%}\")\n",
    "\n",
    "print(f\"\\nEnsemble (avg):\")\n",
    "print(f\"  Quantile Loss: {ql_ensemble:,.0f}\")\n",
    "print(f\"  Mean prediction: {preds_ensemble.mean():,.0f} kg\")\n",
    "print(f\"  Under-predictions: {np.sum(preds_ensemble < y_val.values)/len(y_val):.1%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Target: 75-80% under-predictions for quantile 0.2\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7255e29c",
   "metadata": {},
   "source": [
    "## üîÆ Generate Competition Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdb37974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating GPU predictions...\n",
      "This will take 5-10 minutes...\n",
      "\n",
      "  5,000/30,450\n",
      "  5,000/30,450\n",
      "  10,000/30,450\n",
      "  10,000/30,450\n",
      "  15,000/30,450\n",
      "  15,000/30,450\n",
      "  20,000/30,450\n",
      "  20,000/30,450\n",
      "  25,000/30,450\n",
      "  25,000/30,450\n",
      "  30,000/30,450\n",
      "  30,000/30,450\n",
      "\n",
      "‚úÖ Predictions generated!\n",
      "\n",
      "======================================================================\n",
      "PREDICTION STATISTICS\n",
      "======================================================================\n",
      "\n",
      "CatBoost GPU:\n",
      "  Mean: 22,423 kg\n",
      "  Median: 22,412 kg\n",
      "  Zeros: 0.0%\n",
      "\n",
      "XGBoost GPU:\n",
      "  Mean: 101,299 kg\n",
      "  Median: 21,715 kg\n",
      "  Zeros: 3.5%\n",
      "\n",
      "Ensemble:\n",
      "  Mean: 61,861 kg\n",
      "  Median: 22,084 kg\n",
      "  Zeros: 0.0%\n",
      "\n",
      "‚úÖ Predictions generated!\n",
      "\n",
      "======================================================================\n",
      "PREDICTION STATISTICS\n",
      "======================================================================\n",
      "\n",
      "CatBoost GPU:\n",
      "  Mean: 22,423 kg\n",
      "  Median: 22,412 kg\n",
      "  Zeros: 0.0%\n",
      "\n",
      "XGBoost GPU:\n",
      "  Mean: 101,299 kg\n",
      "  Median: 21,715 kg\n",
      "  Zeros: 3.5%\n",
      "\n",
      "Ensemble:\n",
      "  Mean: 61,861 kg\n",
      "  Median: 22,084 kg\n",
      "  Zeros: 0.0%\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for competition\n",
    "# Remove timezone to match the data we loaded\n",
    "pred_start_date = pd.to_datetime('2025-01-01')\n",
    "prediction_mapping['forecast_end_date'] = pd.to_datetime(prediction_mapping['forecast_end_date'])\n",
    "prediction_mapping['horizon_days'] = (prediction_mapping['forecast_end_date'] - pd.to_datetime('2025-01-01')).dt.days\n",
    "\n",
    "predictions_catboost_list = []\n",
    "predictions_xgb_list = []\n",
    "\n",
    "print(\"Generating GPU predictions...\")\n",
    "print(\"This will take 5-10 minutes...\\n\")\n",
    "\n",
    "for idx, row in prediction_mapping.iterrows():\n",
    "    rm_id = row['rm_id']\n",
    "    horizon_days = row['horizon_days']\n",
    "    \n",
    "    features = calculate_advanced_features_v2(\n",
    "        receivals, purchase_orders, materials,\n",
    "        rm_id, pred_start_date, horizon_days\n",
    "    )\n",
    "    \n",
    "    X_pred = pd.DataFrame([features])[feature_cols].fillna(0)\n",
    "    \n",
    "    if CATBOOST_AVAILABLE:\n",
    "        pred_cat = model_catboost.predict(X_pred)[0]\n",
    "        predictions_catboost_list.append(max(0, pred_cat))\n",
    "    \n",
    "    pred_xgb = model_xgb.predict(xgb.DMatrix(X_pred))[0]\n",
    "    predictions_xgb_list.append(max(0, pred_xgb))\n",
    "    \n",
    "    if (idx + 1) % 5000 == 0:\n",
    "        print(f\"  {idx + 1:,}/30,450\")\n",
    "\n",
    "predictions_xgb_arr = np.array(predictions_xgb_list)\n",
    "\n",
    "if CATBOOST_AVAILABLE:\n",
    "    predictions_catboost_arr = np.array(predictions_catboost_list)\n",
    "    predictions_ensemble_arr = (predictions_catboost_arr + predictions_xgb_arr) / 2\n",
    "else:\n",
    "    predictions_ensemble_arr = predictions_xgb_arr\n",
    "\n",
    "print(\"\\n‚úÖ Predictions generated!\")\n",
    "\n",
    "# Statistics\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PREDICTION STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if CATBOOST_AVAILABLE:\n",
    "    print(f\"\\nCatBoost GPU:\")\n",
    "    print(f\"  Mean: {predictions_catboost_arr.mean():,.0f} kg\")\n",
    "    print(f\"  Median: {np.median(predictions_catboost_arr):,.0f} kg\")\n",
    "    print(f\"  Zeros: {np.sum(predictions_catboost_arr == 0)/len(predictions_catboost_arr):.1%}\")\n",
    "\n",
    "print(f\"\\nXGBoost GPU:\")\n",
    "print(f\"  Mean: {predictions_xgb_arr.mean():,.0f} kg\")\n",
    "print(f\"  Median: {np.median(predictions_xgb_arr):,.0f} kg\")\n",
    "print(f\"  Zeros: {np.sum(predictions_xgb_arr == 0)/len(predictions_xgb_arr):.1%}\")\n",
    "\n",
    "print(f\"\\nEnsemble:\")\n",
    "print(f\"  Mean: {predictions_ensemble_arr.mean():,.0f} kg\")\n",
    "print(f\"  Median: {np.median(predictions_ensemble_arr):,.0f} kg\")\n",
    "print(f\"  Zeros: {np.sum(predictions_ensemble_arr == 0)/len(predictions_ensemble_arr):.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b1cb65",
   "metadata": {},
   "source": [
    "## üíæ Save Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "966ecfef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved: submission_gpu_catboost.csv\n",
      "‚úÖ Saved: submission_gpu_xgboost.csv\n",
      "‚úÖ Saved: submission_gpu_ensemble.csv\n",
      "\n",
      "======================================================================\n",
      "FINAL COMPARISON\n",
      "======================================================================\n",
      "\n",
      "V4 (LightGBM tuned): mean ~67,000 kg ‚Üí Score: 13,978 (43rd)\n",
      "GPU Ensemble: mean ~61,861 kg ‚Üí Score: ???\n",
      "\n",
      "Expected improvement: 20-30%\n",
      "Target score: ~9,000-11,000\n",
      "\n",
      "======================================================================\n",
      "\n",
      "üéØ RECOMMENDATIONS:\n",
      "  1. Try submission_gpu_ensemble.csv first\n",
      "  2. If too high, try submission_gpu_catboost.csv\n",
      "  3. If still too high, scale down by 0.8x\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Save submissions\n",
    "if CATBOOST_AVAILABLE:\n",
    "    submission_catboost = pd.DataFrame({\n",
    "        'ID': range(1, len(predictions_catboost_arr) + 1),\n",
    "        'predicted_weight': predictions_catboost_arr\n",
    "    })\n",
    "    submission_catboost.to_csv('submission_gpu_catboost.csv', index=False)\n",
    "    print(\"‚úÖ Saved: submission_gpu_catboost.csv\")\n",
    "\n",
    "submission_xgb = pd.DataFrame({\n",
    "    'ID': range(1, len(predictions_xgb_arr) + 1),\n",
    "    'predicted_weight': predictions_xgb_arr\n",
    "})\n",
    "submission_xgb.to_csv('submission_gpu_xgboost.csv', index=False)\n",
    "print(\"‚úÖ Saved: submission_gpu_xgboost.csv\")\n",
    "\n",
    "submission_ensemble = pd.DataFrame({\n",
    "    'ID': range(1, len(predictions_ensemble_arr) + 1),\n",
    "    'predicted_weight': predictions_ensemble_arr\n",
    "})\n",
    "submission_ensemble.to_csv('submission_gpu_ensemble.csv', index=False)\n",
    "print(\"‚úÖ Saved: submission_gpu_ensemble.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nV4 (LightGBM tuned): mean ~67,000 kg ‚Üí Score: 13,978 (43rd)\")\n",
    "print(f\"GPU Ensemble: mean ~{predictions_ensemble_arr.mean():,.0f} kg ‚Üí Score: ???\")\n",
    "print(f\"\\nExpected improvement: 20-30%\")\n",
    "print(f\"Target score: ~9,000-11,000\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nüéØ RECOMMENDATIONS:\")\n",
    "print(\"  1. Try submission_gpu_ensemble.csv first\")\n",
    "print(\"  2. If too high, try submission_gpu_catboost.csv\")\n",
    "print(\"  3. If still too high, scale down by 0.8x\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlu25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
